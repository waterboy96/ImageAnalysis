{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial: How to describe a set of images in terms of visual clusters"
      ],
      "metadata": {
        "id": "smhE5FgHYlXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a tutorial on how to process a set of images with a pretrained computer vision model to obtain latent representations, cluster them with K-means, and calculate how many photos belong to each category. This example was adapted by the following [example](https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34) from Gabe Flomo. If you are having problems with the tutorial, or have any questions contact me at sebtop@kt.dtu.dk, [@littlecodelover](https://twitter.com/littlecodelover) or [LinkedIn](https://www.linkedin.com/in/sebastian-topalian-3b1743204/)."
      ],
      "metadata": {
        "id": "wdOdzhpDaGgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "Here we use images related to the following publication(s):\n",
        "- ECO-STP Conference: Quantitative Image Analysis of Biosolids: Evaluating morphological parameters versus visual features # Insert DOI here\n",
        "\n",
        "- Full journal paper: Title # Insert DOI here"
      ],
      "metadata": {
        "id": "iG5YT2-HWlg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Change runtime type\n",
        "Before running the code you should change the runtime to a runtime type with a GPU. This helps us speed up the inference from the image model used later on. In the menu above select runtime, change runtime type and then from the hardware accelerator drop down menu select GPU."
      ],
      "metadata": {
        "id": "2IeCMfXX4bD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download zip file and unzip\n",
        "\n",
        "First we download pictures from a sample of inactivated biomass. These photos were taken and segmented with an Ocelloscope and accompanying software from [ParticleTech](https://particletech.dk)."
      ],
      "metadata": {
        "id": "Ha5wZ25rAwLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/waterboy96/ImageAnalysis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57LrgIjD3Hu0",
        "outputId": "1b60f9ed-0364-491d-967e-0f8accfe0b77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageAnalysis'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), 5.93 MiB | 6.32 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ImageAnalysis/Particles.zip"
      ],
      "metadata": {
        "id": "N3bdq-Md7nst"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Import necessary packages"
      ],
      "metadata": {
        "id": "awvDuuIgA8kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from keras.applications import Xception\n",
        "from keras.models import Model\n",
        "from keras.utils import image_dataset_from_directory, load_img\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "0G8thU874zvY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load Xception model and generate feature vectors"
      ],
      "metadata": {
        "id": "Ph7-OjwoAtvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Xception()\n",
        "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Mwn7v94OQO",
        "outputId": "d6eff592-ab91-4068-a14b-0a61ca087c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "54452224/91884032 [================>.............] - ETA: 1s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = image_dataset_from_directory('Particles', batch_size= 64, image_size = (299,299), labels = None, shuffle = False, label_mode= None)\n",
        "df = pd.DataFrame(model.predict(ds))"
      ],
      "metadata": {
        "id": "UGW7H_vt5Lvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ddR2tILT7C9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a vector of length 2048 for each picture in our sample. These vectors represent the output of the penultimate layer in the Xception model which can be used to describe our images."
      ],
      "metadata": {
        "id": "lyi4cQc5BLbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Reduce dimensionality with PCA"
      ],
      "metadata": {
        "id": "K_hKv6tRBpxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scaled = (df-df.mean())/df.std()\n",
        "df_scaled.dropna(axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "7C-JdZVNDUhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(df_scaled)"
      ],
      "metadata": {
        "id": "ShIzZh9bAgTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pick a threshold of how much of the variance that should be retained. Here we select 99%. Reducing the dimensionality of the vectors helps with the computational time of clustering in the next step."
      ],
      "metadata": {
        "id": "wYx01nSSKOJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variance_threshold = 0.99\n",
        "\n",
        "plt.plot([x for x in range(len(pca.explained_variance_))], np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components', fontweight = 'bold')\n",
        "plt.ylabel('Cumulative Variance Explained Ratio', fontweight = 'bold')\n",
        "ax = plt.gca()\n",
        "plt.title('Skree Plot for PCA on Xception Feature Vectors', fontweight = 'bold')\n",
        "plt.axvline(np.argmax(np.cumsum(pca.explained_variance_ratio_)>variance_threshold), linestyle = '--', c = 'red')\n",
        "plt.text(700,0.7,f'{variance_threshold*100}% Variance Threshold at {np.argmax(np.cumsum(pca.explained_variance_ratio_)>variance_threshold)}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sOwavWI0CHBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An argument could be made to reduce the threshold to the point where the curve evens out for further reduction."
      ],
      "metadata": {
        "id": "Et7mclEgJ-vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.argmax(np.cumsum(pca.explained_variance_ratio_)>variance_threshold)"
      ],
      "metadata": {
        "id": "8Q1zD6ZiLol-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_threshold = PCA(n_components=threshold)"
      ],
      "metadata": {
        "id": "47h55pxPJp9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCs = pca_threshold.fit_transform(df_scaled)"
      ],
      "metadata": {
        "id": "FsRJwLoLMpJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. K-means clustering and cluster counting"
      ],
      "metadata": {
        "id": "wFQFANJDMEM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KM = KMeans(n_clusters = 6)"
      ],
      "metadata": {
        "id": "A700-Oh_MBYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KM.fit(PCs)"
      ],
      "metadata": {
        "id": "FLrV7TonMLoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels = KM.predict(PCs)"
      ],
      "metadata": {
        "id": "D6ZNundMP7NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Count_values(X,Clusters):\n",
        "    return pd.DataFrame([(len(X[X == i])/len(X)) for i in range(Clusters)]).T"
      ],
      "metadata": {
        "id": "fmt5BJhuP9Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Count_values(labels,6)"
      ],
      "metadata": {
        "id": "sdyD2vTWQJ5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the distribution between the different clusters for this sample is quite uneven. Cluster 0, 1 have above 5% while 4, 6, 11, 14 have below 0.01%.\n",
        "\n",
        "This vector is what we in the beforementioned literature reffered to as cluster participation vectors which showed better performance for predicitng reject turbidity than both clusters built on conventional morphological parameters such as length, area etc. and also better performance than the mean of said morphological parameters."
      ],
      "metadata": {
        "id": "L421jyK9QfyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualisation of clusters"
      ],
      "metadata": {
        "id": "Lj_siWuPRGOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "particles = []\n",
        "\n",
        "with os.scandir('Particles')as files:\n",
        "    for file in files:\n",
        "        if file.name.endswith('.png'):\n",
        "            particles.append(file.name)"
      ],
      "metadata": {
        "id": "wC76qk4QMh-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "particles = sorted(['Particles/'+p for p in particles if not p.startswith('.')])"
      ],
      "metadata": {
        "id": "2lZMCQuMMyQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups = {}\n",
        "\n",
        "for file, cluster in zip(particles, labels):\n",
        "    if cluster not in groups.keys():\n",
        "        groups[cluster] = []\n",
        "        groups[cluster].append(file)\n",
        "    else:\n",
        "        groups[cluster].append(file)"
      ],
      "metadata": {
        "id": "bRzOl-7LPUai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def view_cluster(cluster):\n",
        "    plt.figure(figsize = (25,25));\n",
        "    # gets the lits of filenames for a cluster\n",
        "    files = groups[cluster]\n",
        "    # only allow up to 30 images to be shown at a time\n",
        "    if len(files) > 30:\n",
        "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
        "        files = files[:29]\n",
        "        \n",
        "    # plot each image in the cluster\n",
        "    for index, file in enumerate(files):\n",
        "        plt.subplot(10,10, index+1);\n",
        "        img = load_img(file)\n",
        "        img = np.array(img)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "M-DsryOwORsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view_cluster(1) "
      ],
      "metadata": {
        "id": "FHXD3XPrOykw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try changing the above number to visualise a different cluster. (Don't forget cluster 0)"
      ],
      "metadata": {
        "id": "V1Y-SKabZq9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "That is it for this tutorial. If you have a particularly large number of photos I would suggest considering down sampling as K-means scales poorly. For questions contact me at sebtop@kt.dtu.dk, [@littlecodelover](https://twitter.com/littlecodelover) or [LinkedIn](https://www.linkedin.com/in/sebastian-topalian-3b1743204/).\n",
        "\n"
      ],
      "metadata": {
        "id": "vW0R0rBbS9l0"
      }
    }
  ]
}